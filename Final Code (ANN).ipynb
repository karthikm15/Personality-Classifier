{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"conda_tensorflow_p36","language":"python","name":"conda_tensorflow_p36"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Final Code (ANN).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"-cVeVyxv1D-9"},"source":["# Libraries Used\n","import collections\n","from collections import OrderedDict\n","from imutils import face_utils\n","import numpy as np\n","import argparse\n","import imutils\n","import dlib\n","import cv2\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import tensorflow as tf\n","from random import random\n","import keras\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VC5tZfk1PxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615821026175,"user_tz":420,"elapsed":53371,"user":{"displayName":"Karthik Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeZI506CDkDIyhAClP9oL5Mc8vkibyG3cGUA61jw=s64","userId":"10968410699437700240"}},"outputId":"9cae3d25-8f9e-47e1-c37a-cada04bf0c29"},"source":["drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M6j7ntx8Ctc-"},"source":["# compiled_stacked_coors.csv - for every training/validation image, the 68 points were taken out (and only the points pertaining to the nose were saved)\n","#  - the 68 points essentially represent the facial landmarks of a person's face that are pertinent to defining facial features (e.g. the nose, the mouth, etc.)\n","#. - We honed in \n","df = pd.read_csv('/content/gdrive/MyDrive/personality_datasets/compiled_stacked_coors.csv')\n","df = df.T\n","dictionary = df.to_dict()\n","\n","# converting .csv to list format - this data ('[(90, 112), (90, 120)]') was stored as a string so this is just changing it to a list so that Python can use it\n","compiled_stacked_coors = []\n","compiled_stacked_coors_values = []\n","\n","for i in range(0, len(df)-1):\n","  string = dictionary[0][str(i)]\n","  index_value = dictionary[1][str(i)]\n","\n","  split_string = string.split(', (')\n","  split_string[0] = split_string[0][2:]\n","  split_string[len(split_string)-1] = split_string[len(split_string)-1][:-1]\n","\n","  not_paranthesis = True\n","  new_string = []\n","  for i in range(len(split_string)):\n","    split_string[i] = '(' + split_string[i]\n","    string = split_string[i]\n","    string = string.split(', ')\n","    if (string[0] == '('):\n","      not_paranthesis = False\n","      continue\n","    string[0] = string[0][1:]\n","    string[1] = string[1][:-1]\n","    if (not string[0].isnumeric() or not string[1].isnumeric() or not index_value.isnumeric()):\n","      not_paranthesis = False\n","    new_string.append([int(string[0])/150.0, int(string[1])/150.0])\n","\n","  if (not_paranthesis):\n","    if (len(new_string) == 9):\n","      compiled_stacked_coors.append(new_string)\n","      compiled_stacked_coors_values.append(int(index_value))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hf_b8d1jKsmB"},"source":["# Randomly shuffling the dataset\n","c = list(zip(compiled_stacked_coors, compiled_stacked_coors_values))\n","random.shuffle(c)\n","compiled_stacked_coors, compiled_stacked_coors_values = zip(*c)\n","\n","# Splitting up train and validation\n","train = compiled_stacked_coors[:int(0.6*len(compiled_stacked_coors))]\n","train_values = compiled_stacked_coors_values[:int(0.6*len(compiled_stacked_coors_values))]\n","valid = compiled_stacked_coors[int(0.6*len(compiled_stacked_coors)):]\n","valid_values = compiled_stacked_coors_values[int(0.6*len(compiled_stacked_coors_values)):]\n","\n","# Converting to one-hot values so that no bias is added to the data based on big_nose being 1\n","train_values = tf.one_hot(train_values, depth = 2)\n","valid_values = tf.one_hot(valid_values, depth = 2)\n","\n","# Converting to a Tensorflow dataset and splitting based on batch size\n","train_dataset = tf.data.Dataset.from_tensor_slices((list(train), train_values)).shuffle(len(train_values)).batch(64)\n","val_dataset = tf.data.Dataset.from_tensor_slices((list(valid), valid_values)).shuffle(len(valid_values)).batch(64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe35N_LeKsmC"},"source":["# Making a relatively simple model - just a series of linear hidden layers that sequentially decrease in node side - 'sigmoid' was arbitrarily chosen as the activation function\n","model = keras.Sequential([\n","    keras.layers.Reshape(target_shape=(18*1,), input_shape=(9,2)),\n","    keras.layers.Dense(units=128, activation='sigmoid'),\n","    keras.layers.Dense(units=64, activation='sigmoid'),\n","    keras.layers.Dense(units=32, activation='sigmoid'),\n","    keras.layers.Dense(units=10, activation='sigmoid'),\n","    keras.layers.Dense(units=2, activation='sigmoid')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTAAi2RXKsmD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615821047584,"user_tz":420,"elapsed":15251,"user":{"displayName":"Karthik Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeZI506CDkDIyhAClP9oL5Mc8vkibyG3cGUA61jw=s64","userId":"10968410699437700240"}},"outputId":"25da226e-e18f-4565-8ead-0ff04371ec7f"},"source":["# Compiling and running the model\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), \n","              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit(\n","    train_dataset.repeat(), \n","    epochs=10, \n","    steps_per_epoch=500,\n","    batch_size = 32,\n","    validation_data=val_dataset.repeat(), \n","    validation_steps = 2\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","500/500 [==============================] - 2s 3ms/step - loss: 0.6969 - accuracy: 0.5007 - val_loss: 0.6854 - val_accuracy: 0.5625\n","Epoch 2/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6941 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4844\n","Epoch 3/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5093 - val_loss: 0.6989 - val_accuracy: 0.4609\n","Epoch 4/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.5023 - val_loss: 0.6925 - val_accuracy: 0.5234\n","Epoch 5/10\n","500/500 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5006 - val_loss: 0.6942 - val_accuracy: 0.4766\n","Epoch 6/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6938 - val_accuracy: 0.4531\n","Epoch 7/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.5011 - val_loss: 0.6911 - val_accuracy: 0.5391\n","Epoch 8/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.4951 - val_loss: 0.6906 - val_accuracy: 0.5391\n","Epoch 9/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6940 - accuracy: 0.4971 - val_loss: 0.6916 - val_accuracy: 0.5391\n","Epoch 10/10\n","500/500 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6927 - val_accuracy: 0.5156\n"],"name":"stdout"}]}]}